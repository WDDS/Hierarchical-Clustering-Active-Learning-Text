{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "MAX_LEAFS = 256\n",
    "\n",
    "class Tree(object):\n",
    "    \n",
    "    def __init__(self, tree_hierarchy, clusters_predict=[], mode=\"sklearn\", sentences_all_classes=None, true_classes_all=None):\n",
    "        \"\"\"\n",
    "        @param mode : Two possible values\n",
    "            - \"FBE\" : Tree object for Feedback Explorer output\n",
    "            - \"sklearn\" : Tree object for scikit learn output\n",
    "        \n",
    "        @param sentences_all_classes : List of all possible classes occuring in the sentences file (only for mode FBE)\n",
    "        @param true_labels_all : All occuring true labels (mesh codes) of the documents/abstracts\n",
    "        \"\"\"\n",
    "        self.tree = None\n",
    "        if mode in [\"sklearn\", \"FBE\"]:\n",
    "            self.mode = mode\n",
    "        else:\n",
    "            raise ValueError(\"Provided mode '{}' is not supported\".format(mode))\n",
    "        self.tree_hierarchy = tree_hierarchy # pandas dataframe with tree structure coming from hierarchical clustering\n",
    "        self.n_nodes = 0 # updated by calling self.count_nodes()\n",
    "        self.n_leafs = 0 # updated by calling self.count_leafs()\n",
    "        self.temp_n_leafs = 1 # In mode 'FBE' helps to construct the tree with the right number of nodes\n",
    "        self.clusters_predict = clusters_predict # predicted cluster for each document\n",
    "        self.unique_cluster_predict = list(set(clusters_predict)) # list of all classes to calculate performance metrices\n",
    "        self.leaf_nodes = [] # list of all leaf nodes\n",
    "        self.sentences_all_classes = sentences_all_classes # List of all classes occuring in sentences (phrases.parquet)\n",
    "        self.true_classes_documents = true_classes_all.values.tolist() # list of true labels (mesh codes) in the abstracts\n",
    "        self.true_classes_documents_unique = list(set(true_classes_all)) # all possible occuring true labels (mesh codes) in the abstracts\n",
    "        self.precision_all_nodes = [] # macro\n",
    "        self.precision_all_nodes_weighted = []\n",
    "        self.precision_macro = None \n",
    "        self.precision_micro = None\n",
    "        self.recall_all_classes = []\n",
    "        self.recall_all_classes_weighted = []\n",
    "        self.recall_macro = None\n",
    "        self.recall_micro = None\n",
    "        self.F1_macro = None\n",
    "        self.F1_micro = None\n",
    "        \n",
    "        \n",
    "    def _build_tree(self, node, current_depth=None):\n",
    "        if self.mode == \"sklearn\":\n",
    "            if node.node_id in self.tree_hierarchy[\"node_id\"].values: # if node not leaf\n",
    "                treeChildren = self.tree_hierarchy[self.tree_hierarchy[\"node_id\"] == node.node_id]\n",
    "                node.add_child(Node(Id=treeChildren[\"left\"].values[0], depth=node.depth + 1, parent=node))\n",
    "                node.add_child(Node(Id=treeChildren[\"right\"].values[0], depth=node.depth + 1, parent=node))\n",
    "                self._build_tree(node.children[0])\n",
    "                self._build_tree(node.children[1])\n",
    "            else:\n",
    "                return node\n",
    "            return node\n",
    "            #print(node)\n",
    "#            #print(\"\\tcurrent_depth: {}; temp_nleafs: {}\".format(current_depth, self.temp_n_leafs))\n",
    "#            if node.depth == current_depth and self.temp_n_leafs < MAX_LEAFS:\n",
    "#                if node.node_id in self.tree_hierarchy[\"node_id\"].values: # if node not leaf\n",
    "#                    treeChildren = self.tree_hierarchy[self.tree_hierarchy[\"node_id\"] == node.node_id]\n",
    "#                    self.temp_n_leafs -= 1 # lose one leaf because it is split into two new leafs\n",
    "#                    node.add_child(Node(Id=treeChildren[\"left\"].values[0], depth=node.depth + 1, parent=node))\n",
    "#                    self.temp_n_leafs += 1 # creates new child\n",
    "#                    node.add_child(Node(Id=treeChildren[\"right\"].values[0], depth=node.depth + 1, parent=node))\n",
    "#                    self.temp_n_leafs += 1 # creates new child\n",
    "#            else:\n",
    "#                if len(node.children) == 2 and self.temp_n_leafs < MAX_LEAFS:\n",
    "#                    self._build_tree(node.children[0], current_depth)\n",
    "#                    self._build_tree(node.children[1], current_depth)\n",
    "#            return node\n",
    "        elif self.mode == \"FBE\": \n",
    "            # Only create node if node is in current depth level\n",
    "            if node.depth == current_depth and self.temp_n_leafs < MAX_LEAFS:\n",
    "                treeChildren = self.tree_hierarchy.iloc[node.node_id].children\n",
    "                # FBE tree is not a perfect binary tree, some nodes don't create children any more\n",
    "                if len(treeChildren) > 0:\n",
    "                    cluster_child_one = self.tree_hierarchy.iloc[treeChildren[0]].filterValue[0]\n",
    "                    cluster_child_two = self.tree_hierarchy.iloc[treeChildren[1]].filterValue[0]\n",
    "                    # Some nodes from nodes.json are empty: no sentences is going through them\n",
    "                    # Only create node in tree when there is a sentence running through it\n",
    "                    if cluster_child_one in self.sentences_all_classes:\n",
    "                        self.temp_n_leafs -= 1 # lose one leaf because it is split into two new leafs\n",
    "                        node.add_child(Node(Id=treeChildren[0], depth=node.depth + 1, parent=node, cluster_label=cluster_child_one))\n",
    "                        self.temp_n_leafs += 1\n",
    "                        if cluster_child_two in sentences_all_classes:\n",
    "                            node.add_child(Node(Id=treeChildren[1], depth=node.depth + 1, parent=node, cluster_label=cluster_child_two))\n",
    "                            self.temp_n_leafs += 1\n",
    "                    elif cluster_child_two in sentences_all_classes:\n",
    "                        self.temp_n_leafs -= 1 # lose one leaf because it is split into two new leafs\n",
    "                        node.add_child(Node(Id=treeChildren[1], depth=node.depth + 1, parent=node, cluster_label=cluster_child_two))\n",
    "                        self.temp_n_leafs += 1                    \n",
    "            else:\n",
    "                if len(node.children) == 1 and self.temp_n_leafs < MAX_LEAFS:\n",
    "                    self._build_tree(node.children[0], current_depth)\n",
    "                elif len(node.children) == 2 and self.temp_n_leafs < MAX_LEAFS:\n",
    "                    self._build_tree(node.children[0], current_depth)\n",
    "                    self._build_tree(node.children[1], current_depth)\n",
    "            return node\n",
    "\n",
    "    def _update_leaf_to_root(self, node, abstract_id, class_predict):\n",
    "        \"\"\" Updates node and all its ancestors up to the root with the abstract's id and the predicted class\"\"\"\n",
    "        node.update_node(abstract_id, class_predict)\n",
    "        if node.parent != None: # Root has no parent\n",
    "            self._update_leaf_to_root(node.parent, abstract_id, class_predict)\n",
    "    \n",
    "#    def set_build_tree(self,node, maxDepth=None):\n",
    "#        \"\"\" Builds the tree and sets the variable tree.\"\"\"\n",
    "#        \n",
    "#        if self.mode == \"sklearn\":\n",
    "#            tree = self._build_tree(node, maxDepth)       \n",
    "#        if self.mode == \"FBE\":\n",
    "#            self.temp_n_nodes = 1\n",
    "#            depth = 0\n",
    "#            # build tree by level: create first all children for level 1, then level 2... \n",
    "#            # Prevents that a tree creates children just in one branch and always goes deeper in case of a max number of leavese\n",
    "#            while depth < maxDepth and self.temp_n_leafs < MAX_LEAFS:\n",
    "#                tree = self._build_tree(node, depth)\n",
    "#                depth += 1\n",
    "#        \n",
    "#        assert isinstance(tree, Node)\n",
    "#        self.tree = tree\n",
    "\n",
    "    def set_build_tree(self,node):\n",
    "        \"\"\" Builds the tree and sets the variable tree.\"\"\"  \n",
    "\n",
    "        # tree with MAX_LEAFS leafs is constructed. \n",
    "        # For sklearn add to each leaf its cluster label based on the children in the tree object from sklearn AgglomerativeClustering\n",
    "        self.leaf_nodes = []\n",
    "        if self.mode == \"sklearn\":\n",
    "            tree = self._build_tree(node) # construct whole tree\n",
    "            tree = self._get_cluster_labels_for_leafs(tree) # get labels for leafs\n",
    "            tree = self._cut_nodes_from_leafs(tree) # cut nodes from bottom of the tree until only leafs with a unique cluster_label exist (Number leaves = MAX_LEAFS)\n",
    "        elif self.mode == \"FBE\":\n",
    "            self.temp_n_nodes = 1\n",
    "            depth = 0\n",
    "            # build tree by level: create first all children for level 1, then level 2... \n",
    "            # Prevents that a tree creates children just in one branch and always goes deeper in case of a max number of leavese\n",
    "            while self.temp_n_leafs < MAX_LEAFS:\n",
    "                #print(\"\\ndepth: {}, n_nodes: {}\".format(depth, self.temp_n_nodes))\n",
    "                tree = self._build_tree(node, depth)\n",
    "                depth += 1\n",
    "\n",
    "        assert isinstance(tree, Node)\n",
    "        self.tree = tree\n",
    "        print(\"Count nodes: {}; leafs: {}\".format(self.count_nodes(), self.count_leafs()))\n",
    "\n",
    "\n",
    "    def _get_cluster_labels_for_leafs(self, node):\n",
    "        \"\"\" \n",
    "            Get's the cluster labels for each leafs using the cluster labels assigned by\n",
    "            the output of the sklearn agglomerative clustering algorithm.\n",
    "        \"\"\"        \n",
    "        if len(node.children) == 0: #leaf\n",
    "            cluster_label = self.clusters_predict[node.node_id]\n",
    "            node.set_clusterLabel(cluster_label)\n",
    "        else: # no leaf\n",
    "            self._get_cluster_labels_for_leafs(node.children[0])\n",
    "            self._get_cluster_labels_for_leafs(node.children[1])\n",
    "        return node\n",
    "    \n",
    "    def _cut_nodes_from_leafs(self, node):\n",
    "        \"\"\" \n",
    "            Children of nodes, who are leafs and have the same cluster_label, are cut off\n",
    "            and the parent node takes the cluster label of its children.\n",
    "            This is done recursively until there are only leafs with unique cluster_labels \n",
    "            Number of leaves = MAX_LEAFS\n",
    "        \n",
    "        \"\"\"\n",
    "        if len(node.children) > 0: \n",
    "            left_child = node.children[0]\n",
    "            right_child = node.children[1]\n",
    "            if left_child.cluster_label is None: # left child is not leaf \n",
    "                self._cut_nodes_from_leafs(left_child)\n",
    "            if right_child.cluster_label is None: # right child is not leaf \n",
    "                self._cut_nodes_from_leafs(right_child)\n",
    "\n",
    "            # should be updated now\n",
    "            left_child = node.children[0]\n",
    "            right_child = node.children[1]\n",
    "            if left_child.cluster_label == right_child.cluster_label and left_child.cluster_label is not None:\n",
    "                node.children = []\n",
    "                node.cluster_label = left_child.cluster_label\n",
    "                return node\n",
    "\n",
    "        return node    \n",
    "\n",
    "        \n",
    "    def fitTree(self, node, data):\n",
    "        \"\"\" Updates all the nodes of the tree according to the clustering from bottom to top \"\"\"\n",
    "\n",
    "        assert isinstance(node, Node)\n",
    "        if len(node.children) > 0: # no leaf\n",
    "            for child in node.children:\n",
    "                self.fitTree(child, data)\n",
    "        else: # leaf\n",
    "            if self.mode == \"sklearn\": \n",
    "                leaf_cluster_label = node.cluster_label\n",
    "                abstract_hits = data[data[\"class_predict\"] == leaf_cluster_label]\n",
    "                for i, row in abstract_hits.iterrows():\n",
    "                    leaf_abstract_id = row.name\n",
    "                    leaf_abstract_class_true = row.mesh_ui_diab # true class \n",
    "                    self._update_leaf_to_root(node, leaf_abstract_id, leaf_abstract_class_true)\n",
    "            elif self.mode == \"FBE\": # several documents per leaf\n",
    "                leaf_cluster_label = node.cluster_label\n",
    "                abstract_hits = data[data[\"uniqueCluster\"] == leaf_cluster_label]\n",
    "                for i, row in abstract_hits.iterrows():\n",
    "                    leaf_abstract_id = row[\"id\"]\n",
    "                    leaf_abstract_class_true = row[\"mesh_ui_diab\"]\n",
    "                    self._update_leaf_to_root(node, leaf_abstract_id, leaf_abstract_class_true)\n",
    "            else: \n",
    "                print(\"ERROR: mode should be one of ['sklearn', 'FBE']\")\n",
    "        return node\n",
    "        \n",
    "    def _walk_count_nodes(self, node):\n",
    "        self.n_nodes += 1\n",
    "        \n",
    "        for child in node.children:\n",
    "            self._walk_count_nodes(child)            \n",
    "            \n",
    "    def count_nodes(self, tree=None):\n",
    "        self.n_nodes = 0\n",
    "        if tree == None:\n",
    "            self._walk_count_nodes(self.tree)\n",
    "        else:\n",
    "            self._walk_count_nodes(tree)\n",
    "        return self.n_nodes\n",
    "    \n",
    "    def _walk_count_leafs(self, node):\n",
    "        if node.children == []:\n",
    "            self.n_leafs += 1\n",
    "            self.leaf_nodes.append(node)\n",
    "        else:\n",
    "            for child in node.children:\n",
    "                self._walk_count_leafs(child)\n",
    "                \n",
    "    def count_leafs(self, tree=None):\n",
    "        self.n_leafs = 0\n",
    "        self.leaf_nodes = []\n",
    "        if tree == None:\n",
    "            self._walk_count_leafs(self.tree)\n",
    "        else:\n",
    "            self._walk_count_leafs(tree)\n",
    "        return self.n_leafs\n",
    "    \n",
    "    def _walk_leaf_nodes(self, node):\n",
    "        if node.children == []:\n",
    "            self.leaf_nodes.append(node)\n",
    "        else:\n",
    "            for child in node.children:\n",
    "                self._walk_leaf_nodes(child)\n",
    "    \n",
    "    def get_leaf_nodes(self):\n",
    "        self.leaf_nodes = []\n",
    "        self._walk_leaf_nodes(self.tree)\n",
    "        return self.leaf_nodes\n",
    "    \n",
    "    def _walk_precision(self, node):\n",
    "        node_precision = node.get_precision()\n",
    "        self.precision_all_nodes.append(node_precision)\n",
    "        self.precision_all_nodes_weighted.append(node_precision / node.counts)\n",
    "        for child in node.children:\n",
    "            self._walk_precision(child)\n",
    "            \n",
    "    def get_precision(self):\n",
    "        self.precision_all_nodes = []\n",
    "        self._walk_precision(self.tree)\n",
    "        self.precision_macro = np.mean(self.precision_all_nodes)\n",
    "        self.precision_micro = np.mean(self.precision_all_nodes_weighted)\n",
    "        return {\"prec_macro\" : self.precision_macro\n",
    "                , \"prec_micro\" : self.precision_micro}\n",
    "\n",
    "        \n",
    "    def get_recall(self):\n",
    "        \n",
    "        def _walk_recall(node, c):\n",
    "            \"\"\" Get cluster with max documents of class c \"\"\"\n",
    "            occ = node.count_class_occurrence(c)\n",
    "            if occ > self.temp_recall :\n",
    "                self.temp_recall = occ\n",
    "                #print(\"\\ttemp_recall: {}\".format(self.temp_recall))\n",
    "            for child in node.children:\n",
    "                _walk_recall(child, c)\n",
    "        \n",
    "        for c in self.true_classes_documents_unique:\n",
    "            N_c = self.true_classes_documents.count(c)\n",
    "            #print(\"c: {}, N_c : {}\".format(c, N_c))\n",
    "            self.temp_recall = 0.0 \n",
    "#            _walk_recall(self.tree, c)\n",
    "            # TODO: check if it is right!\n",
    "            # # start with children; otherwise recalls for all classes will be highest in root\n",
    "            _walk_recall(self.tree.children[0], c) \n",
    "            _walk_recall(self.tree.children[1], c)\n",
    "            #print(\"Max count: {}; recall: {}\".format(self.temp_recall, self.temp_recall / self.true_classes_documents.count(c)))\n",
    "            recall = self.temp_recall / N_c\n",
    "            self.recall_all_classes.append(recall) #len(self.unique_cluster_predict))\n",
    "            self.recall_all_classes_weighted.append(recall / N_c)\n",
    "        self.recall_macro = np.mean(self.recall_all_classes)\n",
    "        self.recall_micro = np.mean(self.recall_all_classes_weighted)\n",
    "        return {\"recall_macro\" : self.recall_macro\n",
    "                ,\"recall_micro\" : self.recall_micro}\n",
    "    \n",
    "    def get_F1(self):\n",
    "        precision = self.get_precision()\n",
    "        recall = self.get_recall()        \n",
    "        \n",
    "        self.F1_macro = 2*precision[\"prec_macro\"]*recall[\"recall_macro\"] / (precision[\"prec_macro\"] + recall[\"recall_macro\"])\n",
    "        self.F1_micro = 2*precision[\"prec_micro\"]*recall[\"recall_micro\"] / (precision[\"prec_micro\"] + recall[\"recall_micro\"])\n",
    "        return {\"F1_macro\":self.F1_macro\n",
    "               ,\"F1_micro\":self.F1_micro}\n",
    "    \n",
    "    def get_performances(self):\n",
    "        precision = self.get_precision()\n",
    "        recall = self.get_recall()\n",
    "        F1 = self.get_F1()\n",
    "        return({\n",
    "            \"prec_micro\" : precision[\"prec_micro\"]\n",
    "            ,\"prec_macro\" : precision[\"prec_macro\"]            \n",
    "            ,\"recall_micro\" : recall[\"recall_micro\"]\n",
    "            ,\"recall_macro\" : recall[\"recall_macro\"]\n",
    "            ,\"F1_micro\" : F1[\"F1_micro\"]\n",
    "            ,\"F1_macro\" : F1[\"F1_macro\"]        })\n",
    " \n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    \"Generic tree node.\"\n",
    "    def __init__(self, Id, depth, parent=None, cluster_label=None, children=[]):\n",
    "        self.node_id = Id\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.depth = depth\n",
    "        self.cluster_label = cluster_label # In case FBE: this is the filterValue in the leafs\n",
    "        self.abstracts = [] # PMID's of abstracts \n",
    "        self.true_classes = [] # True classes for each abstract\n",
    "        self.counts = 0\n",
    "        self.recall = None\n",
    "        self.precision = None \n",
    "        self.F1 = None\n",
    "        if children is not None:\n",
    "            for child in children:\n",
    "                self.add_child(child)\n",
    "                \n",
    "    def __repr__(self):\n",
    "        return \"Node id: {} (depth: {}, cluster_label: {})\".format(self.node_id, self.depth, self.cluster_label)\n",
    "    \n",
    "    def add_child(self, node):\n",
    "        assert isinstance(node, Node)\n",
    "        self.children.append(node)\n",
    "        \n",
    "    def set_clusterLabel(self, clusterLabel):\n",
    "        self.cluster_label = clusterLabel\n",
    "        \n",
    "    def pretty_print(self, depth=0):\n",
    "        \n",
    "        if self.depth == depth: \n",
    "            print(\"Node: {}, Parent: {} (Depth: {}, counts: {}, cluster_label: {}) | Children: {}\".format(self.node_id, self.parent, self.depth, self.counts, self.cluster_label, self.children))\n",
    "            print(\"\\tAbstracts: {}\".format(Counter(self.abstracts)))\n",
    "            print(\"\\ttrue_classes: {}\".format(Counter(self.true_classes)))\n",
    "        else:\n",
    "            for child in self.children:\n",
    "                child.pretty_print(depth)\n",
    "            \n",
    "            \n",
    "    def update_node(self, abstract_id, true_class):\n",
    "        \"\"\" Updates the abstracts and its true class label running through this node \"\"\"\n",
    "        self.abstracts.append(abstract_id)\n",
    "        self.true_classes.append(true_class)\n",
    "        self.counts += 1\n",
    "        \n",
    "        \n",
    "    def get_precision(self):\n",
    "        count = Counter(self.true_classes)\n",
    "        mostFrequent = max(self.true_classes, key=count.get)\n",
    "        prec = self.true_classes.count(mostFrequent) / self.counts\n",
    "        return prec\n",
    "\n",
    "    def count_class_occurrence(self, c):\n",
    "        return self.true_classes.count(c)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree nodes: (55910, 3)\n",
      "   node_id   left  right\n",
      "0    55911  24005  54126\n",
      "1    55912   8019  35641\n",
      "2    55913  22173  29395\n",
      "3    55914  17366  43982\n",
      "4    55915  16539  23169\n",
      "data size: (55911, 9)\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]\n",
      "['D003921', 'D003925', 'D016640', 'D003929', 'D056731', 'D048909', 'D011236', 'D006944', 'D003924', 'D017719', 'D014929', 'D000071698', 'D058065', 'D003922', 'D016883', 'D003928', 'D003920', 'D003926', 'D003930', 'D003923', 'D005320']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PMID</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>date</th>\n",
       "      <th>mesh_ui</th>\n",
       "      <th>mesh_mh</th>\n",
       "      <th>mesh_ui_diab</th>\n",
       "      <th>mesh_mh_diab</th>\n",
       "      <th>class_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22783714</td>\n",
       "      <td>Evaluation of oxidative stress among coronary ...</td>\n",
       "      <td>OBJECTIVES\\nDetermination of the superoxide di...</td>\n",
       "      <td>2011-12</td>\n",
       "      <td>D000368,D002097,D002318,D003124,D003925,D00491...</td>\n",
       "      <td>Aged,C-Reactive Protein,Cardiovascular Disease...</td>\n",
       "      <td>D003925</td>\n",
       "      <td>Diabetic Angiopathies</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6933815</td>\n",
       "      <td>Ocular complications to diabetes and their tre...</td>\n",
       "      <td>Ocular complications to diabetes may be descri...</td>\n",
       "      <td>1980</td>\n",
       "      <td>D002386,D002387,D003930,D006801,D053685,D008028</td>\n",
       "      <td>Cataract,Cataract Extraction,Diabetic Retinopa...</td>\n",
       "      <td>D003930</td>\n",
       "      <td>Diabetic Retinopathy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PMID                                              title  \\\n",
       "0  22783714  Evaluation of oxidative stress among coronary ...   \n",
       "1   6933815  Ocular complications to diabetes and their tre...   \n",
       "\n",
       "                                            abstract     date  \\\n",
       "0  OBJECTIVES\\nDetermination of the superoxide di...  2011-12   \n",
       "1  Ocular complications to diabetes may be descri...     1980   \n",
       "\n",
       "                                             mesh_ui  \\\n",
       "0  D000368,D002097,D002318,D003124,D003925,D00491...   \n",
       "1    D002386,D002387,D003930,D006801,D053685,D008028   \n",
       "\n",
       "                                             mesh_mh mesh_ui_diab  \\\n",
       "0  Aged,C-Reactive Protein,Cardiovascular Disease...      D003925   \n",
       "1  Cataract,Cataract Extraction,Diabetic Retinopa...      D003930   \n",
       "\n",
       "            mesh_mh_diab  class_predict  \n",
       "0  Diabetic Angiopathies             33  \n",
       "1   Diabetic Retinopathy              3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        \n",
    "data = pd.read_parquet(\"/home/adrian/workspace/Hierarchical-Clustering-Active-Learning-Text/outputs/diabetes_abstracts_HC_output.parquet\")\n",
    "data.index = data.index.get_level_values(None)\n",
    "data.index.name = \"PMID\"\n",
    "data = data.reset_index()\n",
    "#data = pd.read_parquet(\"/home/adrian/workspace/Hierarchical-Clustering-Active-Learning-Text/diabetes_abstracts_HC_output_10Examples.parquet\")\n",
    "#data = pd.read_parquet(\"/home/adrian/workspace/Hierarchical-Clustering-Active-Learning-Text/diabetes_abstracts_HC_output_30Examples.parquet\")\n",
    "\n",
    "HC_tree = pd.read_parquet('/home/adrian/workspace/Hierarchical-Clustering-Active-Learning-Text/outputs/diabetes_abstracts_tree_output.parquet')\n",
    "#HC_tree = pd.read_parquet('/home/adrian/workspace/Hierarchical-Clustering-Active-Learning-Text/diabetes_abstracts_tree_output_10Examples.parquet')\n",
    "#HC_tree = pd.read_parquet('/home/adrian/workspace/Hierarchical-Clustering-Active-Learning-Text/diabetes_abstracts_tree_output_30Examples.parquet')\n",
    "\n",
    "## TEST TREE\n",
    "#data = pd.DataFrame({\"PMID\": [0, 1, 2, 3, 4, 5]\n",
    "#                    , \"class_predict\": [3, 0, 0, 0, 1, 2]}\n",
    "#                   , columns=[\"PMID\", \"class_predict\"]).set_index(\"PMID\")\n",
    "\n",
    "#HC_tree = pd.DataFrame({\"node_id\":[6, 7, 8, 9, 10]\n",
    "#                    , \"left\" : [1, 2, 0, 5, 8]\n",
    "#                    , \"right\" :[3, 6, 4, 7, 9]}\n",
    "#                   , columns=[\"node_id\", \"left\", \"right\"])\n",
    "\n",
    "print(\"Tree nodes: {}\".format(HC_tree.shape))\n",
    "print(HC_tree.head())\n",
    "print(\"data size: {}\".format(data.shape))\n",
    "print(list(set(data[\"class_predict\"])))\n",
    "print(list(set(data[\"mesh_ui_diab\"])))\n",
    "data.head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count nodes: 511; leafs: 256\n",
      "N nodes: 511\n",
      "N leafs: 256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Node id: 110259 (depth: 1, cluster_label: 79),\n",
       " Node id: 16630 (depth: 2, cluster_label: 191),\n",
       " Node id: 3609 (depth: 3, cluster_label: 255),\n",
       " Node id: 16139 (depth: 6, cluster_label: 193),\n",
       " Node id: 55746 (depth: 6, cluster_label: 95),\n",
       " Node id: 27624 (depth: 6, cluster_label: 173),\n",
       " Node id: 42333 (depth: 6, cluster_label: 195),\n",
       " Node id: 24043 (depth: 5, cluster_label: 225),\n",
       " Node id: 33961 (depth: 7, cluster_label: 131),\n",
       " Node id: 52127 (depth: 7, cluster_label: 109),\n",
       " Node id: 760 (depth: 8, cluster_label: 133),\n",
       " Node id: 41929 (depth: 8, cluster_label: 169),\n",
       " Node id: 15721 (depth: 9, cluster_label: 151),\n",
       " Node id: 111137 (depth: 9, cluster_label: 71),\n",
       " Node id: 110388 (depth: 11, cluster_label: 83),\n",
       " Node id: 17634 (depth: 13, cluster_label: 223),\n",
       " Node id: 110990 (depth: 13, cluster_label: 163),\n",
       " Node id: 111536 (depth: 13, cluster_label: 62),\n",
       " Node id: 22561 (depth: 14, cluster_label: 227),\n",
       " Node id: 53499 (depth: 15, cluster_label: 224),\n",
       " Node id: 109752 (depth: 15, cluster_label: 111),\n",
       " Node id: 26278 (depth: 11, cluster_label: 239),\n",
       " Node id: 15867 (depth: 13, cluster_label: 129),\n",
       " Node id: 11915 (depth: 14, cluster_label: 164),\n",
       " Node id: 21227 (depth: 14, cluster_label: 156),\n",
       " Node id: 19423 (depth: 13, cluster_label: 138),\n",
       " Node id: 27610 (depth: 15, cluster_label: 219),\n",
       " Node id: 11421 (depth: 16, cluster_label: 143),\n",
       " Node id: 41552 (depth: 16, cluster_label: 230),\n",
       " Node id: 8751 (depth: 17, cluster_label: 137),\n",
       " Node id: 61882 (depth: 17, cluster_label: 205),\n",
       " Node id: 40868 (depth: 19, cluster_label: 117),\n",
       " Node id: 111133 (depth: 19, cluster_label: 174),\n",
       " Node id: 111539 (depth: 19, cluster_label: 15),\n",
       " Node id: 853 (depth: 20, cluster_label: 249),\n",
       " Node id: 111460 (depth: 20, cluster_label: 244),\n",
       " Node id: 111255 (depth: 18, cluster_label: 194),\n",
       " Node id: 37150 (depth: 19, cluster_label: 197),\n",
       " Node id: 47376 (depth: 20, cluster_label: 233),\n",
       " Node id: 111559 (depth: 20, cluster_label: 6),\n",
       " Node id: 46164 (depth: 17, cluster_label: 247),\n",
       " Node id: 111532 (depth: 17, cluster_label: 17),\n",
       " Node id: 52531 (depth: 18, cluster_label: 231),\n",
       " Node id: 42577 (depth: 19, cluster_label: 132),\n",
       " Node id: 111335 (depth: 20, cluster_label: 211),\n",
       " Node id: 51673 (depth: 21, cluster_label: 220),\n",
       " Node id: 111318 (depth: 21, cluster_label: 172),\n",
       " Node id: 9845 (depth: 20, cluster_label: 171),\n",
       " Node id: 23872 (depth: 22, cluster_label: 251),\n",
       " Node id: 48845 (depth: 22, cluster_label: 186),\n",
       " Node id: 38950 (depth: 22, cluster_label: 167),\n",
       " Node id: 50274 (depth: 22, cluster_label: 159),\n",
       " Node id: 111482 (depth: 20, cluster_label: 53),\n",
       " Node id: 111135 (depth: 22, cluster_label: 84),\n",
       " Node id: 111557 (depth: 22, cluster_label: 13),\n",
       " Node id: 95809 (depth: 22, cluster_label: 99),\n",
       " Node id: 110785 (depth: 23, cluster_label: 218),\n",
       " Node id: 111450 (depth: 23, cluster_label: 81),\n",
       " Node id: 111429 (depth: 20, cluster_label: 55),\n",
       " Node id: 111468 (depth: 21, cluster_label: 59),\n",
       " Node id: 111291 (depth: 22, cluster_label: 78),\n",
       " Node id: 111474 (depth: 23, cluster_label: 63),\n",
       " Node id: 5308 (depth: 24, cluster_label: 154),\n",
       " Node id: 111365 (depth: 24, cluster_label: 75),\n",
       " Node id: 13855 (depth: 20, cluster_label: 199),\n",
       " Node id: 45218 (depth: 21, cluster_label: 207),\n",
       " Node id: 2758 (depth: 23, cluster_label: 183),\n",
       " Node id: 25153 (depth: 24, cluster_label: 158),\n",
       " Node id: 52691 (depth: 24, cluster_label: 252),\n",
       " Node id: 111550 (depth: 26, cluster_label: 8),\n",
       " Node id: 109863 (depth: 27, cluster_label: 103),\n",
       " Node id: 179 (depth: 28, cluster_label: 209),\n",
       " Node id: 10178 (depth: 30, cluster_label: 177),\n",
       " Node id: 111489 (depth: 30, cluster_label: 69),\n",
       " Node id: 41425 (depth: 30, cluster_label: 130),\n",
       " Node id: 14855 (depth: 31, cluster_label: 228),\n",
       " Node id: 111511 (depth: 31, cluster_label: 42),\n",
       " Node id: 111377 (depth: 26, cluster_label: 43),\n",
       " Node id: 111476 (depth: 29, cluster_label: 32),\n",
       " Node id: 111340 (depth: 30, cluster_label: 108),\n",
       " Node id: 111523 (depth: 30, cluster_label: 20),\n",
       " Node id: 15178 (depth: 30, cluster_label: 180),\n",
       " Node id: 111434 (depth: 30, cluster_label: 37),\n",
       " Node id: 111564 (depth: 30, cluster_label: 2),\n",
       " Node id: 111406 (depth: 31, cluster_label: 47),\n",
       " Node id: 111472 (depth: 31, cluster_label: 116),\n",
       " Node id: 34286 (depth: 28, cluster_label: 235),\n",
       " Node id: 4080 (depth: 29, cluster_label: 135),\n",
       " Node id: 111495 (depth: 30, cluster_label: 148),\n",
       " Node id: 32876 (depth: 31, cluster_label: 208),\n",
       " Node id: 111074 (depth: 31, cluster_label: 170),\n",
       " Node id: 2837 (depth: 25, cluster_label: 139),\n",
       " Node id: 111432 (depth: 27, cluster_label: 76),\n",
       " Node id: 19543 (depth: 28, cluster_label: 229),\n",
       " Node id: 110753 (depth: 28, cluster_label: 153),\n",
       " Node id: 111349 (depth: 28, cluster_label: 127),\n",
       " Node id: 29629 (depth: 29, cluster_label: 166),\n",
       " Node id: 111339 (depth: 30, cluster_label: 112),\n",
       " Node id: 111441 (depth: 30, cluster_label: 94),\n",
       " Node id: 107176 (depth: 28, cluster_label: 168),\n",
       " Node id: 35654 (depth: 30, cluster_label: 150),\n",
       " Node id: 17834 (depth: 31, cluster_label: 189),\n",
       " Node id: 111393 (depth: 31, cluster_label: 182),\n",
       " Node id: 39259 (depth: 31, cluster_label: 155),\n",
       " Node id: 111549 (depth: 31, cluster_label: 24),\n",
       " Node id: 111524 (depth: 33, cluster_label: 21),\n",
       " Node id: 109837 (depth: 34, cluster_label: 222),\n",
       " Node id: 111428 (depth: 34, cluster_label: 214),\n",
       " Node id: 39906 (depth: 33, cluster_label: 165),\n",
       " Node id: 111453 (depth: 33, cluster_label: 105),\n",
       " Node id: 54304 (depth: 32, cluster_label: 113),\n",
       " Node id: 21216 (depth: 36, cluster_label: 144),\n",
       " Node id: 31244 (depth: 37, cluster_label: 200),\n",
       " Node id: 110662 (depth: 38, cluster_label: 110),\n",
       " Node id: 110862 (depth: 38, cluster_label: 64),\n",
       " Node id: 111163 (depth: 36, cluster_label: 241),\n",
       " Node id: 19830 (depth: 37, cluster_label: 136),\n",
       " Node id: 111183 (depth: 37, cluster_label: 196),\n",
       " Node id: 43064 (depth: 36, cluster_label: 149),\n",
       " Node id: 111554 (depth: 36, cluster_label: 7),\n",
       " Node id: 111380 (depth: 37, cluster_label: 39),\n",
       " Node id: 111452 (depth: 38, cluster_label: 48),\n",
       " Node id: 111463 (depth: 38, cluster_label: 86),\n",
       " Node id: 111514 (depth: 38, cluster_label: 51),\n",
       " Node id: 111456 (depth: 39, cluster_label: 115),\n",
       " Node id: 111512 (depth: 39, cluster_label: 28),\n",
       " Node id: 111462 (depth: 38, cluster_label: 40),\n",
       " Node id: 111425 (depth: 39, cluster_label: 97),\n",
       " Node id: 111537 (depth: 39, cluster_label: 46),\n",
       " Node id: 3059 (depth: 35, cluster_label: 134),\n",
       " Node id: 111486 (depth: 36, cluster_label: 57),\n",
       " Node id: 111510 (depth: 36, cluster_label: 106),\n",
       " Node id: 55265 (depth: 36, cluster_label: 141),\n",
       " Node id: 111496 (depth: 38, cluster_label: 18),\n",
       " Node id: 54259 (depth: 39, cluster_label: 202),\n",
       " Node id: 111526 (depth: 40, cluster_label: 26),\n",
       " Node id: 109920 (depth: 41, cluster_label: 254),\n",
       " Node id: 111417 (depth: 41, cluster_label: 58),\n",
       " Node id: 111104 (depth: 39, cluster_label: 248),\n",
       " Node id: 111422 (depth: 39, cluster_label: 142),\n",
       " Node id: 111423 (depth: 39, cluster_label: 98),\n",
       " Node id: 111558 (depth: 39, cluster_label: 12),\n",
       " Node id: 39776 (depth: 37, cluster_label: 179),\n",
       " Node id: 25815 (depth: 38, cluster_label: 176),\n",
       " Node id: 111543 (depth: 38, cluster_label: 30),\n",
       " Node id: 50124 (depth: 38, cluster_label: 250),\n",
       " Node id: 111442 (depth: 38, cluster_label: 123),\n",
       " Node id: 48388 (depth: 39, cluster_label: 221),\n",
       " Node id: 111314 (depth: 40, cluster_label: 128),\n",
       " Node id: 26134 (depth: 41, cluster_label: 216),\n",
       " Node id: 111097 (depth: 41, cluster_label: 157),\n",
       " Node id: 111355 (depth: 42, cluster_label: 104),\n",
       " Node id: 111565 (depth: 42, cluster_label: 0),\n",
       " Node id: 111481 (depth: 42, cluster_label: 92),\n",
       " Node id: 111344 (depth: 43, cluster_label: 49),\n",
       " Node id: 111538 (depth: 43, cluster_label: 34),\n",
       " Node id: 111556 (depth: 42, cluster_label: 9),\n",
       " Node id: 108872 (depth: 43, cluster_label: 175),\n",
       " Node id: 111186 (depth: 43, cluster_label: 72),\n",
       " Node id: 111465 (depth: 42, cluster_label: 67),\n",
       " Node id: 111445 (depth: 43, cluster_label: 242),\n",
       " Node id: 111458 (depth: 43, cluster_label: 38),\n",
       " Node id: 10159 (depth: 41, cluster_label: 146),\n",
       " Node id: 16168 (depth: 41, cluster_label: 203),\n",
       " Node id: 111548 (depth: 42, cluster_label: 16),\n",
       " Node id: 20793 (depth: 43, cluster_label: 184),\n",
       " Node id: 110361 (depth: 43, cluster_label: 145),\n",
       " Node id: 111454 (depth: 43, cluster_label: 90),\n",
       " Node id: 111421 (depth: 44, cluster_label: 213),\n",
       " Node id: 111545 (depth: 45, cluster_label: 10),\n",
       " Node id: 7677 (depth: 46, cluster_label: 236),\n",
       " Node id: 111288 (depth: 46, cluster_label: 65),\n",
       " Node id: 111391 (depth: 44, cluster_label: 96),\n",
       " Node id: 111488 (depth: 44, cluster_label: 91),\n",
       " Node id: 111478 (depth: 44, cluster_label: 185),\n",
       " Node id: 109994 (depth: 47, cluster_label: 253),\n",
       " Node id: 111437 (depth: 47, cluster_label: 140),\n",
       " Node id: 111552 (depth: 47, cluster_label: 29),\n",
       " Node id: 111396 (depth: 48, cluster_label: 126),\n",
       " Node id: 23123 (depth: 51, cluster_label: 178),\n",
       " Node id: 110776 (depth: 51, cluster_label: 107),\n",
       " Node id: 111469 (depth: 51, cluster_label: 41),\n",
       " Node id: 111560 (depth: 51, cluster_label: 3),\n",
       " Node id: 111499 (depth: 51, cluster_label: 60),\n",
       " Node id: 111513 (depth: 51, cluster_label: 52),\n",
       " Node id: 1620 (depth: 52, cluster_label: 181),\n",
       " Node id: 111561 (depth: 53, cluster_label: 4),\n",
       " Node id: 111546 (depth: 54, cluster_label: 27),\n",
       " Node id: 111551 (depth: 54, cluster_label: 25),\n",
       " Node id: 111533 (depth: 53, cluster_label: 93),\n",
       " Node id: 111374 (depth: 54, cluster_label: 212),\n",
       " Node id: 92524 (depth: 55, cluster_label: 114),\n",
       " Node id: 111528 (depth: 55, cluster_label: 36),\n",
       " Node id: 14602 (depth: 55, cluster_label: 210),\n",
       " Node id: 110694 (depth: 56, cluster_label: 234),\n",
       " Node id: 111515 (depth: 56, cluster_label: 70),\n",
       " Node id: 111527 (depth: 55, cluster_label: 45),\n",
       " Node id: 111491 (depth: 57, cluster_label: 122),\n",
       " Node id: 111517 (depth: 57, cluster_label: 33),\n",
       " Node id: 110810 (depth: 57, cluster_label: 226),\n",
       " Node id: 111542 (depth: 57, cluster_label: 19),\n",
       " Node id: 111075 (depth: 55, cluster_label: 240),\n",
       " Node id: 111497 (depth: 55, cluster_label: 23),\n",
       " Node id: 111483 (depth: 56, cluster_label: 121),\n",
       " Node id: 111505 (depth: 57, cluster_label: 125),\n",
       " Node id: 111563 (depth: 57, cluster_label: 5),\n",
       " Node id: 111518 (depth: 56, cluster_label: 56),\n",
       " Node id: 111521 (depth: 56, cluster_label: 188),\n",
       " Node id: 110936 (depth: 47, cluster_label: 89),\n",
       " Node id: 111352 (depth: 47, cluster_label: 118),\n",
       " Node id: 111457 (depth: 48, cluster_label: 246),\n",
       " Node id: 111553 (depth: 48, cluster_label: 11),\n",
       " Node id: 111413 (depth: 48, cluster_label: 82),\n",
       " Node id: 111500 (depth: 49, cluster_label: 85),\n",
       " Node id: 111519 (depth: 51, cluster_label: 50),\n",
       " Node id: 111356 (depth: 52, cluster_label: 206),\n",
       " Node id: 111502 (depth: 52, cluster_label: 102),\n",
       " Node id: 111501 (depth: 52, cluster_label: 31),\n",
       " Node id: 111540 (depth: 52, cluster_label: 22),\n",
       " Node id: 111190 (depth: 52, cluster_label: 198),\n",
       " Node id: 104851 (depth: 53, cluster_label: 100),\n",
       " Node id: 111379 (depth: 54, cluster_label: 101),\n",
       " Node id: 111480 (depth: 56, cluster_label: 124),\n",
       " Node id: 111555 (depth: 56, cluster_label: 14),\n",
       " Node id: 111398 (depth: 57, cluster_label: 119),\n",
       " Node id: 111504 (depth: 57, cluster_label: 35),\n",
       " Node id: 111520 (depth: 57, cluster_label: 54),\n",
       " Node id: 111455 (depth: 58, cluster_label: 120),\n",
       " Node id: 111508 (depth: 59, cluster_label: 61),\n",
       " Node id: 111522 (depth: 59, cluster_label: 73),\n",
       " Node id: 49293 (depth: 26, cluster_label: 74),\n",
       " Node id: 29193 (depth: 28, cluster_label: 237),\n",
       " Node id: 109363 (depth: 28, cluster_label: 162),\n",
       " Node id: 38135 (depth: 29, cluster_label: 68),\n",
       " Node id: 44054 (depth: 29, cluster_label: 161),\n",
       " Node id: 55923 (depth: 29, cluster_label: 66),\n",
       " Node id: 111337 (depth: 30, cluster_label: 152),\n",
       " Node id: 111562 (depth: 30, cluster_label: 1),\n",
       " Node id: 18665 (depth: 26, cluster_label: 243),\n",
       " Node id: 52313 (depth: 29, cluster_label: 238),\n",
       " Node id: 111231 (depth: 29, cluster_label: 190),\n",
       " Node id: 111331 (depth: 29, cluster_label: 80),\n",
       " Node id: 20948 (depth: 30, cluster_label: 192),\n",
       " Node id: 111388 (depth: 30, cluster_label: 245),\n",
       " Node id: 1695 (depth: 28, cluster_label: 217),\n",
       " Node id: 110934 (depth: 29, cluster_label: 77),\n",
       " Node id: 30345 (depth: 30, cluster_label: 232),\n",
       " Node id: 111471 (depth: 30, cluster_label: 44),\n",
       " Node id: 12979 (depth: 25, cluster_label: 147),\n",
       " Node id: 58280 (depth: 25, cluster_label: 187),\n",
       " Node id: 6798 (depth: 11, cluster_label: 215),\n",
       " Node id: 19419 (depth: 12, cluster_label: 160),\n",
       " Node id: 111369 (depth: 12, cluster_label: 87),\n",
       " Node id: 110569 (depth: 11, cluster_label: 204),\n",
       " Node id: 13976 (depth: 12, cluster_label: 201),\n",
       " Node id: 43066 (depth: 12, cluster_label: 88)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialise\n",
    "#MAX_LEAFS=6\n",
    "treeClass = Tree(HC_tree, data[\"class_predict\"], mode=\"sklearn\", true_classes_all=data[\"mesh_ui_diab\"])\n",
    "\n",
    "# define root node\n",
    "root = Node(Id=HC_tree[\"node_id\"].max() # In scikit learn, the root node is the one with maximum node id\n",
    "          , depth=0\n",
    "          , parent=None\n",
    "          , children=[])\n",
    "\n",
    "# build tree\n",
    "treeClass.set_build_tree(root)\n",
    "\n",
    "print(\"N nodes: {}\".format(treeClass.count_nodes()))\n",
    "print(\"N leafs: {}\".format(treeClass.count_leafs()))\n",
    "\n",
    "treeClass.leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit tree with abstracts \n",
    "tree_fit = treeClass.fitTree(treeClass.tree, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treeClass.tree.pretty_print(depth=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prec_micro': 0.25291798273811567, 'prec_macro': 0.5603293541866284, 'recall_micro': 0.006298470385543221, 'recall_macro': 0.9999511409627141, 'F1_micro': 0.012290858894573452, 'F1_macro': 0.7182067311303414}\n"
     ]
    }
   ],
   "source": [
    "#print(treeClass.get_precision())\n",
    "#print(treeClass.get_recall())\n",
    "#print(treeClass.get_F1())\n",
    "print(treeClass.get_performances())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load FeedbackExplorer output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2051\n",
      "55911\n",
      "+--------+--------------------+--------------------+\n",
      "|      id|              tokens|               index|\n",
      "+--------+--------------------+--------------------+\n",
      "|28800712|[outcomes,  , ach...|[828 -> [218 -> 2...|\n",
      "| 6989594|[investigation,  ...|[104 -> [146 -> 1...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "fbe_path = \"/home/adrian/tmp/Test_FBE\"\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "sentences = spark.read.load(fbe_path+\"/phrases/\")\n",
    "print(len(sentences.columns))\n",
    "print(sentences.count())\n",
    "\n",
    "df_short = sentences.select(\"id\", \"tokens\", \"index\")\n",
    "#df_short.printSchema()\n",
    "df_short.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tagId</th>\n",
       "      <th>color</th>\n",
       "      <th>annotations</th>\n",
       "      <th>algo</th>\n",
       "      <th>strLinks</th>\n",
       "      <th>strClassPath</th>\n",
       "      <th>names</th>\n",
       "      <th>filterMode</th>\n",
       "      <th>filterValue</th>\n",
       "      <th>...</th>\n",
       "      <th>windowSize</th>\n",
       "      <th>classCenters</th>\n",
       "      <th>cError</th>\n",
       "      <th>childSplitSize</th>\n",
       "      <th>children</th>\n",
       "      <th>hits</th>\n",
       "      <th>metrics</th>\n",
       "      <th>rocCurve</th>\n",
       "      <th>externalClassesFreq</th>\n",
       "      <th>purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Scope</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'tokens': ['aggregate'], 'tag': 1, 'from': N...</td>\n",
       "      <td>{'value': 'supervised'}</td>\n",
       "      <td>{'0': [1]}</td>\n",
       "      <td>{'1': [0]}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'value': 'allIn'}</td>\n",
       "      <td>[0]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1]</td>\n",
       "      <td>55911</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explorer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'tokens': ['diabetes'], 'tag': 2, 'from': No...</td>\n",
       "      <td>{'value': 'clustering'}</td>\n",
       "      <td>{'1': [2, 3]}</td>\n",
       "      <td>{'2': [0, 1], '3': [0, 1]}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'value': 'anyIn'}</td>\n",
       "      <td>[1]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'2': 0, '3': 1}</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[2, 841]</td>\n",
       "      <td>55911</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Explorer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'tokens': ['diabetes'], 'tag': 4, 'from': No...</td>\n",
       "      <td>{'value': 'clustering'}</td>\n",
       "      <td>{'1': [4, 5]}</td>\n",
       "      <td>{'4': [0, 1, 2], '5': [0, 1, 2]}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{'value': 'anyIn'}</td>\n",
       "      <td>[2]</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'4': 0, '5': 1}</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[3, 656]</td>\n",
       "      <td>43230</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  tagId  color                                        annotations  \\\n",
       "0  In Scope    0.0    NaN  [{'tokens': ['aggregate'], 'tag': 1, 'from': N...   \n",
       "1  Explorer    1.0    NaN  [{'tokens': ['diabetes'], 'tag': 2, 'from': No...   \n",
       "2  Explorer    NaN    NaN  [{'tokens': ['diabetes'], 'tag': 4, 'from': No...   \n",
       "\n",
       "                      algo       strLinks                      strClassPath  \\\n",
       "0  {'value': 'supervised'}     {'0': [1]}                        {'1': [0]}   \n",
       "1  {'value': 'clustering'}  {'1': [2, 3]}        {'2': [0, 1], '3': [0, 1]}   \n",
       "2  {'value': 'clustering'}  {'1': [4, 5]}  {'4': [0, 1, 2], '5': [0, 1, 2]}   \n",
       "\n",
       "  names          filterMode filterValue  ...  windowSize      classCenters  \\\n",
       "0    {}  {'value': 'allIn'}         [0]  ...         0.0              None   \n",
       "1    {}  {'value': 'anyIn'}         [1]  ...         NaN  {'2': 0, '3': 1}   \n",
       "2    {}  {'value': 'anyIn'}         [2]  ...         NaN  {'4': 0, '5': 1}   \n",
       "\n",
       "       cError childSplitSize  children   hits  metrics rocCurve  \\\n",
       "0        None            NaN       [1]  55911       {}       {}   \n",
       "1  [0.0, 0.0]           50.0  [2, 841]  55911       {}       {}   \n",
       "2  [0.0, 0.0]           50.0  [3, 656]  43230       {}       {}   \n",
       "\n",
       "  externalClassesFreq purity  \n",
       "0                  {}     {}  \n",
       "1                  {}     {}  \n",
       "2                  {}     {}  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = pd.read_json(fbe_path+\"/nodes.json\", orient=\"records\")\n",
    "print(nodes.shape)\n",
    "nodes.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in sentences file: 1712\n"
     ]
    }
   ],
   "source": [
    "# Get list with all possible classes in the sentences file\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "join_udf = udf(lambda x: \";\".join(x))\n",
    "sentences_classes_udf = udf(lambda x: \";\".join([str(v) for v in x.keys()]))\n",
    "\n",
    "sentences_transformed = sentences.select(\"id\"\n",
    "                                        , \"tokens\"\n",
    "                                        , sentences_classes_udf('index').alias(\"all_classes\")) \\\n",
    "                                .withColumn(\"tokens\", join_udf(col(\"tokens\"))) \n",
    "                    \n",
    "sentences_pdf = sentences_transformed.toPandas()\n",
    "sentences_pdf[\"id\"] = pd.to_numeric(sentences_pdf[\"id\"])\n",
    "\n",
    "# list of all classes in the sentences file\n",
    "sentences_all_classes = set(pd.to_numeric(sentences_pdf[\"all_classes\"].map(lambda sentence: sentence.split(\";\")).explode()).values)\n",
    "print(\"Number of classes in sentences file: {}\".format(len(sentences_all_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences_pdf: (55911, 4)\n",
      "meshDiab: (55911, 2)\n",
      "merged: (55911, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/deepscience/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>all_classes</th>\n",
       "      <th>PMID</th>\n",
       "      <th>mesh_ui_diab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800712</td>\n",
       "      <td>outcomes; ;achieved; ;with; ;use; ;of; ;a; ;pr...</td>\n",
       "      <td>0;1;3;740;276;7;72;58;828;31</td>\n",
       "      <td>28800712</td>\n",
       "      <td>D017719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6989594</td>\n",
       "      <td>investigation; ;of; ;insulin; ;sensitivity; ;i...</td>\n",
       "      <td>64;0;1;2;1602;228;5;104;1641;10;240;50;20;244;...</td>\n",
       "      <td>6989594</td>\n",
       "      <td>D011236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>524360</td>\n",
       "      <td>ultrastructural; ;pathology; ;of; ;peripheral;...</td>\n",
       "      <td>64;0;1;673;2;228;5;358;104;10;592;241;50;20;24...</td>\n",
       "      <td>524360</td>\n",
       "      <td>D003929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21199315</td>\n",
       "      <td>evidence;-;based; ;interventional; ;pain; ;med...</td>\n",
       "      <td>0;1;3;740;276;7;72;58;828;31</td>\n",
       "      <td>21199315</td>\n",
       "      <td>D003929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24607755</td>\n",
       "      <td>delivery; ;timing; ;and; ;cesarean; ;delivery;...</td>\n",
       "      <td>1232;0;1;194;2;5;453;21;200;10;538;27</td>\n",
       "      <td>24607755</td>\n",
       "      <td>D016640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             tokens  \\\n",
       "0  28800712  outcomes; ;achieved; ;with; ;use; ;of; ;a; ;pr...   \n",
       "1   6989594  investigation; ;of; ;insulin; ;sensitivity; ;i...   \n",
       "2    524360  ultrastructural; ;pathology; ;of; ;peripheral;...   \n",
       "3  21199315  evidence;-;based; ;interventional; ;pain; ;med...   \n",
       "4  24607755  delivery; ;timing; ;and; ;cesarean; ;delivery;...   \n",
       "\n",
       "                                         all_classes      PMID mesh_ui_diab  \n",
       "0                       0;1;3;740;276;7;72;58;828;31  28800712      D017719  \n",
       "1  64;0;1;2;1602;228;5;104;1641;10;240;50;20;244;...   6989594      D011236  \n",
       "2  64;0;1;673;2;228;5;358;104;10;592;241;50;20;24...    524360      D003929  \n",
       "3                       0;1;3;740;276;7;72;58;828;31  21199315      D003929  \n",
       "4              1232;0;1;194;2;5;453;21;200;10;538;27  24607755      D016640  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add true class labels to sentences from data by merge/join \n",
    "sentences_pdf[\"PMID\"] = sentences_pdf[\"id\"]\n",
    "sentences_pdf[\"PMID\"] = pd.to_numeric(sentences_pdf[\"PMID\"])\n",
    "meshDiab = data[[\"PMID\", \"mesh_ui_diab\"]]\n",
    "meshDiab[\"PMID\"] = pd.to_numeric(meshDiab[\"PMID\"])\n",
    "sentences_pd_with_classes = pd.merge(sentences_pdf, meshDiab, on='PMID', how=\"left\")\n",
    "\n",
    "print(\"sentences_pdf: {}\".format(sentences_pdf.shape))\n",
    "print(\"meshDiab: {}\".format(meshDiab.shape))\n",
    "print(\"merged: {}\".format(sentences_pd_with_classes.shape))\n",
    "\n",
    "sentences_pd_with_classes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count nodes: 528; leafs: 256\n",
      "Number leafs: 256\n"
     ]
    }
   ],
   "source": [
    "# initialise\n",
    "treeFBE = Tree(nodes\n",
    "            #, list(set(data[\"class_predict\"]))\n",
    "            , mode=\"FBE\"\n",
    "            , sentences_all_classes=sentences_all_classes\n",
    "            , true_classes_all=sentences_pd_with_classes[\"mesh_ui_diab\"])\n",
    "\n",
    "# define root node\n",
    "root = Node(Id=1, depth=0, parent=None, children=[]) # Id = 1 because start at Explorer \n",
    "\n",
    "# build tree\n",
    "#maxDepth = 10\n",
    "treeFBE.set_build_tree(root)\n",
    "\n",
    "print(\"Number leafs: {}\".format(treeFBE.count_leafs()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N leafs: 256\n",
      "N clusters: 256\n"
     ]
    }
   ],
   "source": [
    "leafs = treeFBE.get_leaf_nodes()\n",
    "print(\"N leafs: {}\".format(len(leafs)))\n",
    "cluster = [leaf.cluster_label for leaf in leafs]\n",
    "print(\"N clusters: {}\".format(len(set(cluster))))\n",
    "for c in cluster:\n",
    "    if c not in sentences_all_classes:\n",
    "        print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N leafs: 256\n",
      "N clusters: 256\n",
      "Unique clusters in sentences: 256\n"
     ]
    }
   ],
   "source": [
    "# Associate cluster to each sentence\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def matchCluster(index_map): \n",
    "    \"\"\" gets for each abstract its unique cluster (filterValue) from the index\"\"\"\n",
    "    return list(set(list(index_map.keys())).intersection(set(cluster)))[0]\n",
    "\n",
    "\n",
    "leafs = treeFBE.get_leaf_nodes()\n",
    "print(\"N leafs: {}\".format(len(leafs)))\n",
    "cluster = [leaf.cluster_label for leaf in leafs]\n",
    "print(\"N clusters: {}\".format(len(set(cluster))))\n",
    "\n",
    "matchCluster_udf = udf(lambda y: matchCluster(y))\n",
    "join_udf = udf(lambda x: \";\".join(x))\n",
    "\n",
    "sentences_transformed = sentences.select(\"id\", \"tokens\", matchCluster_udf('index').alias(\"uniqueCluster\")) \\\n",
    "                    .withColumn(\"tokens\", join_udf(col(\"tokens\"))) \n",
    "                    \n",
    "#sentences.select('index', matchClass_udf('index').atlias(\"uniqueCluster\")).groupby(\"uniqueCluster\").count().show()\n",
    "sentences_pd = sentences_transformed.toPandas()\n",
    "sentences_pd[\"id\"] = pd.to_numeric(sentences_pd[\"id\"])\n",
    "sentences_pd[\"uniqueCluster\"] = pd.to_numeric(sentences_pd[\"uniqueCluster\"])\n",
    "print(\"Unique clusters in sentences: {}\".format(sentences_pd[\"uniqueCluster\"].nunique())) #####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentences_pd: (55911, 4)\n",
      "meshDiab: (55911, 2)\n",
      "sentences_pd_with_classes_uniqueCluster: (55911, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/miniconda3/envs/deepscience/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>uniqueCluster</th>\n",
       "      <th>PMID</th>\n",
       "      <th>mesh_ui_diab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28800712</td>\n",
       "      <td>outcomes; ;achieved; ;with; ;use; ;of; ;a; ;pr...</td>\n",
       "      <td>740</td>\n",
       "      <td>28800712</td>\n",
       "      <td>D017719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6989594</td>\n",
       "      <td>investigation; ;of; ;insulin; ;sensitivity; ;i...</td>\n",
       "      <td>228</td>\n",
       "      <td>6989594</td>\n",
       "      <td>D011236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>524360</td>\n",
       "      <td>ultrastructural; ;pathology; ;of; ;peripheral;...</td>\n",
       "      <td>228</td>\n",
       "      <td>524360</td>\n",
       "      <td>D003929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21199315</td>\n",
       "      <td>evidence;-;based; ;interventional; ;pain; ;med...</td>\n",
       "      <td>740</td>\n",
       "      <td>21199315</td>\n",
       "      <td>D003929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24607755</td>\n",
       "      <td>delivery; ;timing; ;and; ;cesarean; ;delivery;...</td>\n",
       "      <td>538</td>\n",
       "      <td>24607755</td>\n",
       "      <td>D016640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             tokens  uniqueCluster  \\\n",
       "0  28800712  outcomes; ;achieved; ;with; ;use; ;of; ;a; ;pr...            740   \n",
       "1   6989594  investigation; ;of; ;insulin; ;sensitivity; ;i...            228   \n",
       "2    524360  ultrastructural; ;pathology; ;of; ;peripheral;...            228   \n",
       "3  21199315  evidence;-;based; ;interventional; ;pain; ;med...            740   \n",
       "4  24607755  delivery; ;timing; ;and; ;cesarean; ;delivery;...            538   \n",
       "\n",
       "       PMID mesh_ui_diab  \n",
       "0  28800712      D017719  \n",
       "1   6989594      D011236  \n",
       "2    524360      D003929  \n",
       "3  21199315      D003929  \n",
       "4  24607755      D016640  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add true class labels to data by merge/join \n",
    "sentences_pd[\"PMID\"] = sentences_pd[\"id\"]\n",
    "sentences_pd[\"PMID\"] = pd.to_numeric(sentences_pd[\"PMID\"])\n",
    "meshDiab = data[[\"PMID\", \"mesh_ui_diab\"]]\n",
    "meshDiab[\"PMID\"] = pd.to_numeric(meshDiab[\"PMID\"])\n",
    "sentences_pd_with_classes_uniqueCluster = pd.merge(sentences_pd, meshDiab, on='PMID', how=\"left\")\n",
    "print(\"sentences_pd: {}\".format(sentences_pd.shape))\n",
    "print(\"meshDiab: {}\".format(meshDiab.shape))\n",
    "print(\"sentences_pd_with_classes_uniqueCluster: {}\".format(sentences_pd_with_classes.shape))\n",
    "\n",
    "sentences_pd_with_classes_uniqueCluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Node id: 1 (depth: 0, cluster_label: None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeFBE.fitTree(treeFBE.tree, sentences_pd_with_classes_uniqueCluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prec_micro': 0.07665872863135663, 'prec_macro': 0.494841955165603, 'recall_micro': 0.005639166876476844, 'recall_macro': 0.7947587020818961, 'F1_micro': 0.010505526553826057, 'F1_macro': 0.6099251699553135}\n"
     ]
    }
   ],
   "source": [
    "#print(treeFBE.get_precision_macro())\n",
    "#print(treeFBE.get_recall_macro())\n",
    "#print(treeFBE.get_F1())\n",
    "print(treeFBE.get_performances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance scikit learn: \n",
      "{'prec_micro': 0.2529179827381156, 'prec_macro': 0.5603293541866284, 'recall_micro': 0.006298470385543218, 'recall_macro': 0.9999511409627143, 'F1_micro': 0.012290858894573452, 'F1_macro': 0.7182067311303414}\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance scikit learn: \")\n",
    "print(treeClass.get_performances())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaf nodes with no sentences:\n",
      "id: 91; children: []; class: 910; depth: 10; counts: 0; parent: 90 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 96; children: []; class: 911; depth: 10; counts: 0; parent: 90 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 104; children: []; class: 626; depth: 10; counts: 0; parent: 103 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 513; children: []; class: 471; depth: 8; counts: 0; parent: 507 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 517; children: []; class: 877; depth: 8; counts: 0; parent: 515 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 520; children: []; class: 1372; depth: 9; counts: 0; parent: 519 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 551; children: []; class: 1734; depth: 9; counts: 0; parent: 550 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 552; children: []; class: 1735; depth: 9; counts: 0; parent: 550 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 554; children: []; class: 794; depth: 8; counts: 0; parent: 553 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 556; children: []; class: 886; depth: 9; counts: 0; parent: 555 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 600; children: []; class: 968; depth: 8; counts: 0; parent: 599 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 631; children: []; class: 395; depth: 9; counts: 0; parent: 617 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 676; children: []; class: 1143; depth: 9; counts: 0; parent: 674 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 831; children: []; class: 1401; depth: 9; counts: 0; parent: 829 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 934; children: []; class: 1798; depth: 8; counts: 0; parent: 933 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "id: 935; children: []; class: 1799; depth: 8; counts: 0; parent: 933 \n",
      "abstracts: []; predicted_classes: []\n",
      "\n",
      "Empty DataFrame\n",
      "Columns: [id, tokens, uniqueClass]\n",
      "Index: []\n",
      "name                                                            Explorer\n",
      "tagId                                                                NaN\n",
      "color                                                                NaN\n",
      "annotations            [{'tokens': ['diabetes'], 'tag': 1164, 'from':...\n",
      "algo                                             {'value': 'clustering'}\n",
      "strLinks                                             {'1': [1164, 1165]}\n",
      "strClassPath           {'1164': [0, 320, 344, 46, 1, 910, 2, 17, 12, ...\n",
      "names                                                                 {}\n",
      "filterMode                                            {'value': 'anyIn'}\n",
      "filterValue                                                        [910]\n",
      "maxTopWords                                                            6\n",
      "windowSize                                                           NaN\n",
      "classCenters                                      {'1164': 0, '1165': 1}\n",
      "cError                                                        [0.0, 0.0]\n",
      "childSplitSize                                                        50\n",
      "children                                                        [92, 95]\n",
      "hits                                                                   0\n",
      "metrics                                                               {}\n",
      "rocCurve                                                              {}\n",
      "externalClassesFreq                                                   {}\n",
      "purity                                                                {}\n",
      "Name: 91, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TESST\n",
    "\n",
    "def wwwalk(node):\n",
    "    print(node.class_label)\n",
    "    if node.class_label == 496:\n",
    "        node.pretty_print()\n",
    "    else:\n",
    "        for child in node.children:\n",
    "            wwwalk(child)\n",
    "\n",
    "print(\"Leaf nodes with no sentences:\")\n",
    "leafs = treeFBE.get_leaf_nodes()\n",
    "for leaf in leafs:\n",
    "    if len(leaf.abstracts) < 1:\n",
    "        print(\"id: {}; children: {}; class: {}; depth: {}; counts: {}; parent: {} \".format(leaf.node_id, leaf.children, leaf.class_label, leaf.depth, leaf.counts, leaf.parent))\n",
    "        print('abstracts: {}; true_classes: {}'.format(leaf.abstracts, leaf.true_classes))\n",
    "        print()\n",
    "\n",
    "print(sentences_pd[sentences_pd[\"uniqueCluster\"] == 910]) #497\n",
    "print(nodes.iloc[91])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#treeFBE.tree.pretty_print(1)\n",
    "#root.pretty_print(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|uniqueClass|count|\n",
      "+-----------+-----+\n",
      "|       1159|   21|\n",
      "|       1090|  234|\n",
      "|        296|   51|\n",
      "|        691|   33|\n",
      "|        125|    3|\n",
      "|        666|  256|\n",
      "|       1280|  334|\n",
      "|        124| 1199|\n",
      "|        718|  312|\n",
      "|        740| 1173|\n",
      "|        169|   41|\n",
      "|        747|   46|\n",
      "|       1425|   19|\n",
      "|        577|    5|\n",
      "|        272|   25|\n",
      "|         54|  968|\n",
      "|        282|    7|\n",
      "|        232|    1|\n",
      "|        483|   27|\n",
      "|       1158|    5|\n",
      "+-----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences.select('index', matchClass_udf('index').alias(\"uniqueCluster\")).groupby(\"uniqueCluster\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_leaf_to_root(node, abstract_id, class_predict):\n",
    "    node.update_node(abstract_id, class_predict)\n",
    "    if node.parent != None:\n",
    "        _update_leaf_to_root(node.parent, abstract_id, class_predict)\n",
    "\n",
    "def fitTree(node, data):\n",
    "    \"\"\" Updates all the nodes of the tree according to the clustering \"\"\"\n",
    "\n",
    "    assert isinstance(node, Node)\n",
    "    if len(node.children) > 0: # no leaf\n",
    "        for child in node.children:\n",
    "            fitTree(child, data)\n",
    "    else:\n",
    "        leaf_class = node.class_label\n",
    "        abstract_hits = data[data[\"uniqueClass\"] == leaf_class]\n",
    "#        print(\"leaf_class: {}\".format(leaf_class))\n",
    "#        print(abstract_hits.shape)\n",
    "        for i, row in abstract_hits.iterrows():\n",
    "            leaf_abstract_id = row[\"id\"]\n",
    "            leaf_abstract_class_predict = row[\"uniqueClass\"]\n",
    "            _update_leaf_to_root(node, leaf_abstract_id, leaf_abstract_class_predict)\n",
    "\n",
    "    return node\n",
    "\n",
    "#fitted_tree = fitTree(treeFBE.tree, sentences_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-54-100f47e3da18>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-100f47e3da18>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    df_short.select(udf((index:Map[Int, Map[Int, Int]]) => {index.keys.toSet.intersect(classes.toSet).toSeq} ).apply(col(\"index\"))#.as(\"uniqueClass\")).groupBy(\"uniqueClass\").count.show()\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "df_short.select(udf((index:Map[Int, Map[Int, Int]]) => {index.keys.toSet.intersect(classes.toSet).toSeq} ).apply(col(\"index\"))#.as(\"uniqueClass\")).groupBy(\"uniqueClass\").count.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tokens</th>\n",
       "      <th>uniqueClass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, tokens, uniqueClass]\n",
       "Index: []"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
